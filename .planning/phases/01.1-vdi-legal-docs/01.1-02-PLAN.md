---
phase: 01.1-vdi-legal-docs
plan: 02
type: execute
wave: 2
depends_on: ["01.1-01"]
files_modified: [scripts/ingest-vdi-docs.ts, src/types/index.ts, src/lib/pinecone/index.ts, src/app/api/chat/route.ts]
autonomous: false
---

<objective>
Ingest Tier 1 VDI guidance documents and integrate with chat search.

Purpose: Add classified VDI documents to Pinecone and enable citation in chat responses.
Output: vdi_doc vectors in Pinecone, search integration, LLM prompt updated for citations.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
@~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01.1-vdi-legal-docs/01.1-01-SUMMARY.md

# For ingestion patterns:
@scripts/ingest-vdi-faq.ts
@src/lib/pinecone/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create VDI document ingestion script</name>
  <files>scripts/ingest-vdi-docs.ts</files>
  <action>
Create ingestion script that:

1. **Read manifest**: Load `data/vdi-content-manifest.json`
2. **Filter Tier 1 & 2**: Only process tier 1 and tier 2 items
3. **For each document**:
   - If PDF: Download and extract full text with pdf-parse
   - If HTML page: Fetch and extract main content with cheerio
4. **Chunk content**: Split into ~1500 char chunks with 200 char overlap (PDF content can be long)
5. **Generate embeddings**: Use text-embedding-004 (same as FAQ script)
6. **Upsert to Pinecone** with metadata:
   ```typescript
   {
     id: `vdi-doc-${docId}-chunk-${chunkIndex}`,
     values: embedding,
     metadata: {
       docId: `vdi-doc-${docId}`,
       docType: 'vdi_doc',  // New type, distinct from vdi_faq
       title: item.title,
       text: chunk,
       chunkIndex: chunkIndex,
       totalChunks: totalChunks,
       sourceUrl: item.url,
       tier: item.tier,
       topics: item.topics.join(', ')
     }
   }
   ```

**Implementation notes:**
- Follow ingest-vdi-faq.ts patterns exactly
- Use lazy initialization for Pinecone/GenAI
- Support --dry-run flag
- Rate limiting: 100ms delay every 5 embeddings
- Batch upsert in groups of 100
- Log progress: "Processing {title} ({chunkIndex}/{totalChunks})"
  </action>
  <verify>npx tsx scripts/ingest-vdi-docs.ts --dry-run shows chunk counts per document</verify>
  <done>Script processes manifest and chunks documents correctly</done>
</task>

<task type="auto">
  <name>Task 2: Add vdi_doc type to TypeScript types</name>
  <files>src/types/index.ts</files>
  <action>
Add 'vdi_doc' to all docType unions, same pattern as vdi_faq addition:
- Citation type
- ChunkMetadata type
- LegalDocument type
- Any other docType unions

Also add 'title' and 'chunkIndex' to ChunkMetadata if not present.
  </action>
  <verify>npx tsc --noEmit passes</verify>
  <done>vdi_doc type accepted in all type definitions</done>
</task>

<task type="auto">
  <name>Task 3: Add vdi_doc to search and chat</name>
  <files>src/lib/pinecone/index.ts, src/app/api/chat/route.ts</files>
  <action>
1. **In pinecone/index.ts searchHybrid**:
   - Add vdiDocsK parameter (default 3)
   - Add vdi_doc filter to search
   - Same score threshold as vdi_faq (0.65)

2. **In chat/route.ts**:
   - Add vdi_doc handling in formatSource function (label: "VDI Dokumentas")
   - Update LLM system prompt to cite VDI documents:
     "Jei informacija iš VDI dokumentų (vdi_doc), cituok: „Pagal VDI dokumentą „{title}"...""
   - Handle vdi_doc in context assembly
  </action>
  <verify>Search function accepts vdiDocsK parameter without TypeScript errors</verify>
  <done>vdi_doc integrated into search and chat</done>
</task>

<task type="auto">
  <name>Task 4: Run ingestion</name>
  <files>None (runtime)</files>
  <action>
1. Run: `npx tsx scripts/ingest-vdi-docs.ts`
2. Wait for completion
3. Note total vectors upserted
  </action>
  <verify>Script completes without errors, reports vectors upserted</verify>
  <done>Tier 1 & 2 documents ingested to Pinecone</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>VDI document search integration with chunked PDF content</what-built>
  <how-to-verify>
    1. Run: npm run dev
    2. Go to chat interface
    3. Ask: "Kaip skaičiuojamas vidutinis darbo užmokestis?"
    4. Verify: Response cites VDI document (not just FAQ)
    5. Check: VDI Dokumentas appears in sources
    6. Ask: "Kokie darbo sutarties nutraukimo pagrindai?"
    7. Verify: Termination grounds from atmintinė are cited
  </how-to-verify>
  <resume-signal>Type "approved" to continue, or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] npx tsc --noEmit passes
- [ ] npm run build succeeds
- [ ] VDI documents appear in search results
- [ ] Citations show "VDI Dokumentas" label
</verification>

<success_criteria>
- vdi_doc type fully integrated
- Chunked documents in Pinecone
- Search returns VDI documents
- Chat cites VDI documents correctly
- User verified end-to-end functionality
</success_criteria>

<output>
After completion, create `.planning/phases/01.1-vdi-legal-docs/01.1-02-SUMMARY.md`
</output>
